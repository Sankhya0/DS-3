{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94f6ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for k =  1 :\n",
      "[[ 93  25]\n",
      " [ 19 200]]\n",
      "\n",
      "Accuracy score for k =  1  :\n",
      "0.8694362017804155\n",
      "Confusion Matrix for k =  3 :\n",
      "[[ 92  26]\n",
      " [  9 210]]\n",
      "\n",
      "Accuracy score for k =  3  :\n",
      "0.8961424332344213\n",
      "Confusion Matrix for k =  5 :\n",
      "[[ 92  26]\n",
      " [ 10 209]]\n",
      "\n",
      "Accuracy score for k =  5  :\n",
      "0.8931750741839762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df  =  pd.read_csv('SteelPlateFaults-2class.csv') #reading the csv file\n",
    "\n",
    "data_0 = df[df[\"Class\"]== 0] #creating the database where class  =  0\n",
    "data_1 = df[df[\"Class\"]== 1] #creating the database where class  =  1\n",
    "\n",
    "df_class_0 = data_0.Class # extracting the class column for using in the train_test_split\n",
    "df_class_1 = data_1.Class # extracting the class column for using in the train_test_split\n",
    "\n",
    "del data_1['Class'] # deleting the class column \n",
    "del data_0['Class'] # deleting the class column\n",
    "\n",
    "[X0_train, X0_test, X0_label_train, X0_label_test] = train_test_split(data_0,df_class_0, test_size = 0.3, random_state = 42,shuffle = True) # splitting the data of class  =  0 into trains and test datasets\n",
    "[X1_train, X1_test, X1_label_train, X1_label_test] = train_test_split(data_1,df_class_1, test_size = 0.3, random_state = 42,shuffle = True) # splitting the data of class  =  1 into trains and test datasets\n",
    "\n",
    "X_train = pd.concat((X0_train,X1_train),axis = 0) # creating the train dataset by concatenating the train of class  =  0  and class  =  1\n",
    "X_label_train = pd.concat((X0_label_train,X1_label_train),axis = 0) # creating the new class list for the training model\n",
    "\n",
    "X_test = pd.concat((X0_test,X1_test),axis = 0) # creating the test dataset by concatenating the train of class  =  0  and class  =  1\n",
    "X_label_test = pd.concat((X0_label_test,X1_label_test),axis = 0) # creating the new class list for testing\n",
    "\n",
    "X_train,X_test = pd.concat((X_train,X_label_train), axis  =  1),pd.concat((X_test,X_label_test), axis  =  1) # recreating the complete original dataset\n",
    "\n",
    "X_train.to_csv(\"SteelPlateFaults-train.csv\",index = False) # creating a csv for the training data\n",
    "X_test.to_csv(\"SteelPlateFaults-test.csv\",index = False) # creating a csv for the testing data\n",
    "\n",
    "k = [1,3,5]\n",
    "Accuracy = [] # We will append all the accuracies obtained into this list and use it for part 4 of the question\n",
    "\n",
    "for i in k:\n",
    "    neigh  =  KNeighborsClassifier(n_neighbors = i) # specifying the k nearest neighbours\n",
    "    neigh.fit(X_train, X_label_train) # applying knn to X_train and X_label_train\n",
    "    \n",
    "    predict_data = neigh.predict(X_test) # predicting the class using the train dataset\n",
    "    con_m  =  confusion_matrix(X_label_test, predict_data) # creating the confusion matrix\n",
    "\n",
    "    print('Confusion Matrix for k = ',i,':')\n",
    "    print(con_m)\n",
    "    print()\n",
    "    print('Accuracy score for k = ',i,' :')\n",
    "    print(accuracy_score(X_label_test,predict_data)) # obtaining the accuracy using predicted data and the testing data\n",
    "    Accuracy.append(accuracy_score(X_label_test,predict_data)) # appending to the accuracy list for final use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964afa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for k =  1 :\n",
      "[[111   7]\n",
      " [  6 213]]\n",
      "\n",
      "Accuracy score for k =  1  :\n",
      "0.9614243323442137\n",
      "Confusion Matrix for k =  3 :\n",
      "[[112   6]\n",
      " [  4 215]]\n",
      "\n",
      "Accuracy score for k =  3  :\n",
      "0.9703264094955489\n",
      "Confusion Matrix for k =  5 :\n",
      "[[112   6]\n",
      " [  3 216]]\n",
      "\n",
      "Accuracy score for k =  5  :\n",
      "0.973293768545994\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('SteelPlateFaults-train.csv') # reading the train dataset created earlier\n",
    "df_test = pd.read_csv('SteelPlateFaults-test.csv') # reading the test dataset created earlier\n",
    "\n",
    "for column in df_test:\n",
    "    df_test[column] = (df_test[column]-df_train[column].min())/(df_train[column].max()-df_train[column].min()) # normalizing the test dataset\n",
    "\n",
    "for column in df_train:\n",
    "    df_train[column] = (df_train[column]-df_train[column].min())/(df_train[column].max()-df_train[column].min()) # normalizing the train dataset\n",
    "\n",
    "df_train.to_csv(\"SteelPlateFaults-train-Normalised.csv\",index = False) # creating a csv for the normalized training data\n",
    "df_test.to_csv(\"SteelPlateFaults-test-Normalised.csv\",index = False) # creating a csv for the normalized testing data\n",
    "\n",
    "df_train_1 = pd.read_csv(\"SteelPlateFaults-train-Normalised.csv\")\n",
    "del df_train_1[\"Class\"] # deleting the class column from the train dataset\n",
    "\n",
    "df_test_1 = pd.read_csv('SteelPlateFaults-test-Normalised.csv')\n",
    "del df_test_1[\"Class\"] # deleting the class column from the test dataset\n",
    "\n",
    "k = [1,3,5]\n",
    "for i in k:\n",
    "    neigh  =  KNeighborsClassifier(n_neighbors = i) # specifying the k nearest neighbours\n",
    "    neigh.fit(df_train_1, df_train.Class) # applying knn to X_train and X_label_train\n",
    "\n",
    "    predict_data = neigh.predict(df_test_1) # predicting the class using the train dataset\n",
    "    con_m  =  confusion_matrix(df_test.Class, predict_data) # creating the confusion matrix\n",
    "\n",
    "    print('Confusion Matrix for k = ',i,':')\n",
    "    print(con_m)\n",
    "    print()\n",
    "    print('Accuracy score for k = ',i,' :')\n",
    "    print(accuracy_score(df_test.Class,predict_data)) # obtaining the accuracy using predicted data and the testing data\n",
    "    Accuracy.append(accuracy_score(df_test.Class,predict_data)) # appending to the accuracy list for final use\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f9cc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[102  16]\n",
      " [  2 217]]\n",
      "Accuracy score :\n",
      "0.9465875370919882\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('SteelPlateFaults-train.csv')\n",
    "X_test = pd.read_csv('SteelPlateFaults-test.csv')\n",
    "\n",
    "del X_train['TypeOfSteel_A400']\n",
    "del X_train['TypeOfSteel_A300']\n",
    "del X_test['TypeOfSteel_A400']\n",
    "del X_test['TypeOfSteel_A300']\n",
    "\n",
    "df_test_class = X_test['Class']\n",
    "del X_test['Class']\n",
    "\n",
    "X_train_class0 = X_train[X_train['Class']== 0]\n",
    "X_train_class1 = X_train[X_train['Class']== 1]\n",
    "\n",
    "del X_train_class0['Class']\n",
    "del X_train_class1['Class']\n",
    "\n",
    "Mean_C0 = X_train_class0.mean().values #Getting the mean of the values with class 0\n",
    "Covariance_Class0 = np.cov(X_train_class0.T) #Getting the covariance matrix with class 0\n",
    "Mean_C1 = X_train_class1.mean().values  #Getting the mean of the values with class 1\n",
    "Covariance_Class1 = np.cov(X_train_class1.T) #Getting the covariance matrix with class 0\n",
    "\n",
    "P_C0 = len(X_train_class0)/(len(X_train_class0)+len(X_train_class1)) # Calculating the prior of the probability of C = 0\n",
    "P_C1 = len(X_train_class1)/(len(X_train_class0)+len(X_train_class1)) # Calculating the prior of the probability of C = 1\n",
    "\n",
    "d = len(X_test.columns)\n",
    "\n",
    "\n",
    "# for i in range(len(Covariance_Class1)):\n",
    "#     for j in range(len(Covariance_Class1)):\n",
    "#         if(i!= j):\n",
    "#             Covariance_Class1[i][j] = 0\n",
    "\n",
    "\n",
    "# for i in range(len(Covariance_Class0)):\n",
    "#     for j in range(len(Covariance_Class0)):\n",
    "#         if(i!= j):\n",
    "#             Covariance_Class0[i][j] = 0\n",
    "d = len(X_test.columns)-1\n",
    "\n",
    "Predicted_class = []\n",
    "for x in X_test[X_test.columns].values:\n",
    "    p_x_C0 = 1/(((2*np.pi)**(d/2))*np.linalg.det(Covariance_Class0)**0.5)*np.e**(-0.5*np.dot(np.dot((x-Mean_C0).T,np.linalg.inv(Covariance_Class0)),(x-Mean_C0))) #applying bayes to get likelihood of class 0 \n",
    "    p_x_C1 = 1/(((2*np.pi)**(d/2))*np.linalg.det(Covariance_Class1)**0.5)*np.e**(-0.5*np.dot(np.dot((x-Mean_C1).T,np.linalg.inv(Covariance_Class1)),(x-Mean_C1))) #applying bayes to get likelihood of class 1 \n",
    "    P_x = p_x_C0*P_C0+p_x_C1*P_C1 # Getting the evidence i.e. total probability\n",
    "    P_C0_x = p_x_C0*P_C0/P_x # Getting the posterior probability for class 0\n",
    "    P_C1_x = p_x_C1*P_C1/P_x # Getting the posterior probability for class 1\n",
    "    if (P_C0_x>P_C1_x):\n",
    "        Predicted_class.append(0)\n",
    "    else:\n",
    "        Predicted_class.append(1)\n",
    "\n",
    "\n",
    "print('Confusion Matrix :')\n",
    "print(confusion_matrix(df_test_class,Predicted_class))\n",
    "print('Accuracy score :')\n",
    "print((accuracy_score(df_test_class,Predicted_class)))\n",
    "Accuracy.append(accuracy_score(df_test_class,Predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2d34ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Process  Accuracy\n",
      "0     original knn = 5  0.893175\n",
      "1   normalized knn = 5  0.973294\n",
      "2  bayesian classifier  0.946588\n"
     ]
    }
   ],
   "source": [
    "Accuracy_1 = max(Accuracy[0],Accuracy[1],Accuracy[2])\n",
    "Accuracy_2 = max(Accuracy[3],Accuracy[4],Accuracy[5])\n",
    "Accuracy_3 = Accuracy[6]\n",
    "\n",
    "data = {'Process':['original knn = 5','normalized knn = 5','bayesian classifier'],\n",
    "        'Accuracy':[Accuracy[2],Accuracy[5],Accuracy[6]]} \n",
    "\n",
    "q4 = pd.DataFrame(data)\n",
    "\n",
    "print(q4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fec9b5afb6b6d66e39538aa6e4d3df38d64b5e6e816cd84681faade8907a26a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
